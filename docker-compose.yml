services:
  deepseek-ocr:
    build:
      context: ./docker
      dockerfile: Dockerfile.transformers
    container_name: nunoocr_deepseek
    restart: unless-stopped

    # Uncomment for NVIDIA GPU support
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]
    # runtime: nvidia

    environment:
      # Model configuration
      - MODEL_NAME=deepseek-ai/DeepSeek-OCR
      - HOST=0.0.0.0
      - PORT=8000
      - API_KEY=${API_KEY:-}

      # PyTorch CPU optimizations
      - OMP_NUM_THREADS=4
      - MKL_NUM_THREADS=4
      - TORCH_NUM_THREADS=4

      # Hugging Face settings
      - HF_HOME=/root/.cache/huggingface
      - TRANSFORMERS_CACHE=/root/.cache/huggingface

    ports:
      - "8765:8000"

    volumes:
      # Cache Hugging Face models (persistent)
      - huggingface-cache:/root/.cache/huggingface
      # Optional: logs
      - ./logs:/app/logs

    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 180s  # Give extra time for model download + loading

    # Resource limits (CPU-optimized)
    # Adjust based on your server capacity
    deploy:
      resources:
        limits:
          memory: 12G  # Max 12GB RAM
        reservations:
          memory: 8G   # Reserve 8GB RAM

    shm_size: '2gb'

    networks:
      - ocr-network

networks:
  ocr-network:
    driver: bridge
    name: nunoocr_network

volumes:
  huggingface-cache:
    name: nunoocr_hf_cache
