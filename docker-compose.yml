services:
  deepseek-ocr:
    build:
      context: ./docker
      dockerfile: Dockerfile.python
    container_name: nunoocr_deepseek
    restart: unless-stopped

    # Uncomment for NVIDIA GPU support
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]
    # runtime: nvidia

    environment:
      # Model will auto-download on first run
      - MODEL_NAME=deepseek-ai/DeepSeek-OCR
      - HOST=0.0.0.0
      - PORT=8000
      - API_KEY=${API_KEY:-}
      # vLLM settings
      - VLLM_ALLOW_LONG_MAX_MODEL_LEN=1

    ports:
      - "8765:8000"

    volumes:
      # Cache Hugging Face models
      - huggingface-cache:/root/.cache/huggingface
      # Optional: logs
      - ./logs:/app/logs

    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s  # Give time for model download

    # Resource limits (adjust based on your system)
    shm_size: '2gb'

    networks:
      - ocr-network

networks:
  ocr-network:
    driver: bridge
    name: nunoocr_network

volumes:
  huggingface-cache:
    name: nunoocr_hf_cache
